{"componentChunkName":"component---src-templates-blog-post-blog-post-tsx","path":"/blog/flaky-test-best-prevention-practices","result":{"data":{"contentfulBlogPost":{"id":"197bd3c7-8718-5202-b4b4-e7f87bbd711d","slug":"flaky-test-best-prevention-practices","industry":"Best Practices","title":{"title":"Flaky test: best prevention practices"},"seoTitle":null,"seoDescription":"Arm yourself with our tips to enhance your QA metrics dashboard and elevate your test execution efficiency.","featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4eQDfyCFkL2RPwYbGorwjN/f8c1371ff85238ec12c9636e7ce82110/Flaky.svg"}},"date":"November 21, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Flaky tests are the wild cards in the software testing world. Flaky tests happen when a test often changes its status from passed to failed and vice versa under the same conditions. Flaky tests can cause a lot of delays, questions, and chaos for software developers and QA teams.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Flaky test cases table widget \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal allows to find flaky tests in your runs. For that, create a Flaky test cases table widget in our test automation results dashboard: specify the Launch name and the Launches count for comparison.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg The widget is built by the name of the launch, and not by the filter. To obtain all the data in this widget, make sure that the launches in which you want to address flaky tests have the same name.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Flaky test cases table widget shows the 50 most unstable test cases in the selected launches. This includes not only Failed tests but also tests that change their status from Passed to Failed, from Failed to Passed. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This widget is dynamic, it only needs to be built once, and it will update automatically.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6wnzPPQQjr0Mj5OFxl3u9G\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"When creating the widget, we can also specify whether to include Before and After methods. Before and After methods are preconditions/postconditions, for example, creating test data, and then, after running the tests, cleaning them up. The reason for flakiness is not always within the test itself – the methods can also be flaky. For instance, the test itself might fail if generating test data fails. In the Launch, the reporting may be fine, and the test case would have passed if the Before or After method was functioning correctly.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Therefore, when a certain number of runs have accumulated, especially in the case of large launches, it is challenging to analyze failed automated tests. You can create this widget, investigate the unstable tests, and understand if there is an issue with the Before/After methods. The problem may not be in functionality, but in automation. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Additionally, with the flaky test widget, you can identify issues with the environment or with a specific version or branch. For example, if a test runs on different environments and passes in some, fails in others, you can temporarily remove these tests from the scope until the environment-related issue is resolved, saving time on running and analyzing flaky tests.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"How to avoid flaky tests?\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\nFor those seeking ways to prevent flaky tests, consider the following best practices:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Stable Test Environment\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Check the availability of critical resources for test execution. Control external factors (e.g., system resources, network connectivity).\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Test Isolation\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Decrease the number of connections between tests. It can significantly minimize the risk of instability.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Optimal Test Timing\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Properly plan your tests to ensure optimal performance for your testing environment. Remember about network congestion and system load.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Test Data Management\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Do not use mutable or shared data that can cause flakiness.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Overall, if you know what causes flaky tests and apply best practices to prevent them, you can reduce the impact of flaky tests. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}","references":[{"contentful_id":"6wnzPPQQjr0Mj5OFxl3u9G","__typename":"ContentfulAsset","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=196&h=145&q=50&fm=webp 196w,\nhttps://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=391&h=289&q=50&fm=webp 391w,\nhttps://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=782&h=578&q=50&fm=webp 782w","sizes":"(min-width: 782px) 782px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=782&h=578&q=50&fm=png","srcSet":"https://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=196&h=145&q=50&fm=png 196w,\nhttps://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=391&h=289&q=50&fm=png 391w,\nhttps://images.ctfassets.net/1n1nntnzoxp4/6wnzPPQQjr0Mj5OFxl3u9G/d07fb2995b8caefd94ced9a4d1a0560a/FlakyTests.png?w=782&h=578&q=50&fm=png 782w","sizes":"(min-width: 782px) 782px, 100vw"}},"layout":"constrained","backgroundColor":"#f8f8f8","width":782,"height":578},"description":"Flaky test cases table widget for qa automation dashboard"}]}}},"pageContext":{"slug":"flaky-test-best-prevention-practices"}},"staticQueryHashes":["2021156393","2991584196","520980492"],"slicesMap":{}}