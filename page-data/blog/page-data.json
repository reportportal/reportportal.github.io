{"componentChunkName":"component---src-pages-blog-jsx","path":"/blog","result":{"data":{"allContentfulBlogPost":{"nodes":[{"id":"ee314060-16fa-5339-ab90-d468224f1d4e","slug":"funny-situations-in-testing","date":"October 20th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Software testing can be a bit of a joke sometimes! You never know what’s going to happen! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We have collected comical stories to highlight the humorous side of the serious world of software testing. Let’s read! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Email Extravaganza \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"On one project, automation test report was supposed to arrive in the inbox when test results came back unsatisfactory. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The team tested the functionality, and everything went smoothly. A couple of years later, new QAs joined the team. They decided to revisit the old test cases, maybe thinking the email server was on vacation. Testers began generating fake reports. And guess what? The client started getting emails with weird text! By evening, the client's inbox was overflowing with email mayhem! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It turns out that someone had accidentally hardcoded the customer's email address and forgotten about it. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"So, the crisis averted, and lessons learned! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1rJGd7Z5bqgNEOHaGmki5G\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Emoji Surprise \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"On a typical day, testers asked their colleague for a link to the smoke test results.  \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The tester sent the link. But then, out of nowhere, some URL-ID keys turned into smoking emojis! Everyone tried to click the link with bated breath. But the link was broken, with emojis hidden inside. The team laughed. Our clever tester said, “As you see, it's a 'Smoke' test!” \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4JixwuKz2UcHbQa2CURP0h\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Unintentional Spam \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"On the project where a telehealth system was being built, the testers needed to test out things like user creation, appointment scheduling, and so on. They used random phone numbers and email addresses. But guess what? When they connected it to the SMS gateway, the “random” phone numbers turned out to be real, and actual people started getting SMS notifications about appointments with a venereologist! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"These unsuspecting individuals thought they were getting spam and started complaining. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The client company couldn't believe what was happening, so they urgently bought SIM cards for test purposes. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"79pGknQ2dIlXMqWt8rZFr6\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The “Phantom Mouse” \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"One day, a QA team was examining a video editing software that allowed users to edit, enhance, and export videos. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"A tester encountered a confusing situation: the cursor glided across the screen, pressing buttons without any input. Could it be a ghost? But fear not! It was just a wireless mouse with low battery, sending out random signals, causing chaos in the video software. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Sometimes the solution is simpler than we imagine! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"53NCcaS2JUdFncFettu8O7\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Time-Traveling Timestamp \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"While testing a messaging app, a tester noticed that one of the timestamps showed a message sent from the future. Shocking! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This caused a great deal of confusion among the developers, but they couldn't replicate this issue. The tester tried various combinations but eventually figured out that the date and time on the phone were set incorrectly. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"A simple correction, and voila! Back to the present, my friends. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1ad0p9elvcKrjEpjqus8tS\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"These stories serve as a reminder that even in the serious world of software testing, there's always something to laugh about. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"Funny situations in testing"},"leadParagraph":{"leadParagraph":"Software testing can be a bit of a joke sometimes! You never know what’s going to happen! \n\nWe have collected comical stories to highlight the humorous side of the serious world of software testing. Let’s read! "},"category":["Other"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/5txL6K9hal4rlrRHCCueI9/37e81c2db1753c52cd201370038cea3c/Funny.svg"}}},{"id":"14d869b2-fd5b-5439-aa55-0ce0022eb505","slug":"Deserialization-issue-workaround","date":"September 16th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We would like to highlight that in version 5.7.5 of API Service and Authorization Service we have updated the dependencies.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Unfortunately, the same dependency found its way into different versions, causing a Java error that looks like this: \\\"AuthUtils$SerialUidReplacingInputStream: Potentially Fatal Deserialization Operation\\\" when serializing/deserializing a user class or token.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Example of a stack trace from logs:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"blueBg \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"AuthUtils$SerialUidReplacingInputStream : Potentially Fatal Deserialization Operation.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"\\r\\n\\r\\njava.io.InvalidClassException: Overriding serialized class version mismatch: local serialVersionUID = 550 stream serialVersionUID = 520 \\r\\nat com.epam.ta.reportportal.auth.util.AuthUtils$SerialUidReplacingInputStream.readClassDescriptor(AuthUtils.java:105) \\r\\nat java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1992) \\r\\nat java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1870) \\r\\nat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2201) \\r\\nat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687) \\r\\nat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489) \\r\\nat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447) \\r\\nat java.base/java.util.TreeSet.readObject(TreeSet.java:524) \\r\\nat java.base/jdk.internal.reflect.GeneratedMethodAccessor226.invoke(Unknown Source) \\r\\nat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Everything is functioning well; however, since users are verified for all requests, including reporting, many errors are filling up the Service API log. To prevent this log from excessively cluttering the Docker, additional logging rules need to be configured in Docker's configuration.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We recommend using the following settings in the Docker compose file for the ReportPortal services containers:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"5IaEMQgny0x2KzRGQnZaC6\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"blockquote\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Note 1\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This is a default recommendation from Docker, and you may need to adjust it to fit your project's specific requirements.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"If your installation is via Kubernetes, you don't need to worry about log rotation because Kubernetes already has it configured by default. However, Docker doesn't have log rotation enabled by default, and its JSON log format can quickly consume all available space.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We plan to update Docker compose in the future, so these log settings will be included in the compose file automatically. Until then, if you are using version 5.7.5 or 23.1 with Docker installed, please check how much space the logs are occupying and update the Docker compose file accordingly.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Default paths for checking logs: \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Linux:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" /var/lib/docker/containers/ \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Windows:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" path depends on the way you’ve installed Docker. Please, check \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://docs.docker.com/desktop/troubleshoot/overview/#check-the-logs\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Docker documentation\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\".\\r\\r\\n\\r\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]}"},"title":{"title":"Deserialization issue workaround"},"leadParagraph":{"leadParagraph":"We would like to highlight that in version 5.7.5 of API Service and Authorization Service we have updated the dependencies. Unfortunately, the same dependency found its way into different versions, causing a Java error when serializing/deserializing a user class or token. How can this be fixed?"},"category":["Product"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/3DHvdns0eyniI6qPnrckE3/b24dc5f1ce7668dbc16f65ac36445d3f/Deserialization.svg"}}},{"id":"581a785f-a448-5d49-8c9a-5cac42dd4dda","slug":"tips-and-tricks-for-successful-ci-cd","date":"August 9th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The main goal of CI/CD is to reduce lead time. This is an important metric that shows how quickly a new feature goes into production. With perfect CI, this process can take just a few minutes. What do we need to deliver features with such speed? Here are some recommendations from the EPAM Test Automation community Mikalai Biazruchka, Oleksandr Halichenko, Yauhen Klimiashuk, Dzmitry Prakapuk. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Define a Git branching strategy and environment strategy \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Continuous Delivery/Deployment is the process of validating and delivering a product to pre-production and production environments. This process goes through the available environments. Git branching strategy and environment strategy are interrelated and define the product build process – from which branch to which environment. If the Git branching strategy and environment strategy are not coordinated, then, accordingly, the process of delivering the product to pre-production and production will not be transparent and may exclude the possibility of building a CI/CD process. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Define quality gates \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A quality gate is a set of step-by-step quality checks that help determine if we can proceed to the next stage or not. Examples of quality gates in development include code review, different linters, vulnerability detection via Sonar, and unit tests. Examples of quality gates in automation include smoke tests, running all tests, or some tests on changed objects. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"By the way, \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://reportportal.io/\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"ReportPortal\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\", as a continuous testing platform, has a premium \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://reportportal.io/docs/quality-gates/QualityGatePurpose/\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Quality Gates feature\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\".\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Choose the right CI tool \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The best option would be the tool that comes with the code repository: GitHub Actions for GitHub, Azure Pipelines for Azure DevOps, and GitLab CI for GitLab. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Implement CI/CD as soon as possible \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Ideally, after every developer’s commit, the entire range of checks should be started: static code analysis, unit tests, code style analysis, integration tests, and end-to-end tests, including UI and API. These checks are aimed at building a Continuous Delivery process where we not only collect (integrate) everything but also deploy somewhere or provide artifacts, such as docker images. In the ideal world, each commit should turn into a new deployment to production. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Learn the toolset of the platform you are working with \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Each platform has its own set of commands and tools that are used for CI/CD-specific purposes. It happens that those who work, for example, on .NET do not know the Command-line interface (CLI) very well. Accordingly, a person who does not know the CLI will not be able to create a full-fledged CI process for the platform in question. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use static code analysis\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Each platform has its tools to evaluate code quality. You should not only install them but also pay attention to what they offer because this provides serious feedback that will help to improve the quality of the code and prevent serious errors. These tools are easy to set up and take little time, but their value is significant. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Consider the pipeline's execution time \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Developers expect the CI pipeline to run in less than 30 minutes. This is the best practice now. If the pipeline takes longer, you need to think about how to fix it. This is where caching can help. It speeds up the CI pipeline a lot since we don't have to rebuild dependencies. On the other hand, caching introduces a certain element of instability because the cache may be invalid or outdated, which can lead to unexpected crashes. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use parallel jobs \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Using parallel CI/CD jobs increases productivity. If you can parallelize specific steps without losing the validity of the pipeline's feedback, then it always makes sense to do that. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use detailed logging\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Additional logging helps not only with the development of the CI/CD pipeline but also with its maintenance. When something goes wrong, having granularly split steps inside CI/CD and the correct logging makes finding a problem in the pipeline much easier. It becomes easier to understand what is happening and how it is happening. For example, if we produce some artifact, it would be nice to properly name it so that it is clear what it is, why it is needed, and where it came from. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use a pipeline-as-code approach \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The recommended approach is to create the pipeline in YAML format or the form of JSON or some kind of executable script: it is located next to the code; it is easy for versioning and easy to change. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Inexperienced engineers often use a graphical interface to create a pipeline. This works well, but when something needs to be changed, questions arise: who changed it, what was changed, and when. Besides, if something went wrong after some change, it is problematic to find this change and revert it. Nowadays, almost all major platforms support the pipeline-as-code format, which allows you to write pipelines in text form. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"It may seem difficult at the beginning of using this approach. But once you get comfortable with the syntax, it gives you more flexibility, and becomes more robust. If you need to transfer the pipeline from one project to another, then it will be just copying the file. If a graphical interface is used, it will most likely need to be recreated from scratch, where something can be forgotten, lost or overlooked. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Collaborate with the development team \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Automation should be in cooperation with the development team. Then, it will be possible to build an effective delivery process and avoid gray areas. It is necessary so that the development team can always indicate what should be paid attention to. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Optimize the test set for each stage \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Automate as much as possible but define clear timelines for each stage (sanity – on push, smoke – daily, regression – every week, etc.). Generally, test design is very important to have a well-established CI/CD process. Poorly prepared tests can take a long time to run or check the wrong thing. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Optimize version control system (VCS) flows \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Minimize branching to avoid high efforts on the code merge process. Encourage teams to merge frequently to avoid lots of branches per engineer. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Keep a stable infrastructure for testing \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"It is great when autotests are integrated into the CI/CD pipeline, and at the same time, it is important that the tests run quickly, and the results don't depend on the infrastructure. For example, if we have 8 threads but only 5 browsers available, then use cloud providers (BrowserStack, Mobitru, SauceLabs) to speed up your test execution via parallel execution. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use centralized test reporting tools \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Test automation reporting tools have enough capabilities to analyze test results and provide clear reports to the stakeholders. It is very convenient to have everything in one place and allows you to get the green light earlier. This is also evidence that the Continuous Delivery process is effective. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"By following these tips, you can build effective CI/CD, streamline the development process, and improve software quality. \",\"marks\":[],\"data\":{}}]}]}"},"title":{"title":"Tips and tricks for successful CI/CD"},"leadParagraph":{"leadParagraph":"The main goal of CI/CD is to reduce lead time. This is an important metric that shows how quickly a new feature goes into production. With perfect CI, this process can take just a few minutes. What do we need to deliver features with such speed?"},"category":["Best Practices"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/2oHVDlJakMfnbuLu3VlPe0/59ff51e65b7b15b2d901f461b40d7841/CICD.svg"}}},{"id":"674361dc-575e-5943-9fca-e6dfac42e9d9","slug":"store-more-clean-faster","date":"July 26th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We are glad to announce the changes in the logic of the cleanStorage starting from the version 5.8.1 of Service Jobs and API Service version 5.9.0.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Previously, it was only possible to clear 1 attachment per 1 request to the binary storage, and it was not possible to clear more than 500,000 attachments per 1 job execution. The current implementation allows to clean multiple blobs (200,000) per 1 request to the S3 storage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The chunk_size env variable remains for the service jobs (no changes in the deployment are needed). But under the hood, the job logic is splitting chunk_size value into fixed batches by 200k and processing deletion via a certain number of iterations, which is calculated based on chunk size. If chunk_size = 2 million, then the job will proceed with the deletion with 10 iterations and clean 200k attachments per iteration.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The new logic is 30 times faster for both S3 and MinIO binary storages\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"Haq4WOWQa84702B9xiU56\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Use case 1:\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" if chunk_size is set to 200,000, the cleanStorage job will delete 200,000 MAX attachments from the S3 storage within 1 iteration. If the attachments count in the attacment_deletion table is less than 200,000, then all attachments will be deleted.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Use case 2:\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" if chunk_size is set to 2 million, the cleanStorage job will delete all attachments from the S3 storage within 10 iterations by batches of 200,000 attachments.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1mJFEBfBHwoeQOZe488lu3\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3ZfsczCXTD1mgOo4w6FJpl\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"Nz4JKSIXNW3WKJ6hPCWiv\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Thus, thanks to this implementation, we have significantly optimized the cleanStorage job performance. It keeps your binary storage within limits and allows you not to care about attachment cleaning. Since we've significantly speeded up the cleanup of binaries, we assume that this should completely solve all such problems.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"Store more, clean faster: CleanStorage job optimized for S3 and MinIO"},"leadParagraph":{"leadParagraph":"We are glad to announce the changes in the logic of the cleanStorage starting from the version 5.8.1 of Service Jobs and API Service version 5.9.0."},"category":["Performance improvements"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/UwooAbVwEvmwIRFhUng2c/329deb42838571300f551abc19ac7cd1/brown.svg"}}},{"id":"a1d54a0e-7ed8-5378-9ab7-01179fe531d6","slug":"trends-in-automated-testing-in-2023","date":"June 22nd, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The GPT Gold Rush\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It's undeniable that the emergence of ChatGPT has rocked the entire world and all industries, particularly software development and testing. Large Language Models (LLMs) have been around for a while, but the implementation of such a generative version of an LLM model in a chat format, which maintains conversation and feels like an extremely well-informed companion, has captured people's attention even more.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Machine Learning models existed before the GPT-boom, but we've never identified them with such human-like qualities before. From generating high-quality text for your diploma or article to attempting to generate programming code – it has prompted people to reconsider how we write code or test applications.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"However, there's a subtle yet crucial line in how we use this tool. If we draw an analogy to the early 20th century, our attempts to use generative models mostly resemble efforts to ask the \\\"magic box\\\" – how to make horses faster, or how to optimally feed them on 1,000-mile journeys. In reality, we should be asking it or ourselves – what alternative modes of transport could we create and how can we create them?\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Every company is now trying to find the most valuable use cases for generative models in their work, somewhere to replace routine, monotonous tasks, and in other cases, to completely create everything with them.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Unfortunately, these models are far from the concept of General AI and are not capable of doing all the work for us. But they can certainly assist us in areas of working with text, textual representation of steps, requirements. And even in generating basic actions and models in code.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Can ChatGPT write all the code for you now? It seems unlikely, at least for the time being. We can see this in the example of Co-pilot, which has access to almost all the codebases in the world inside GitHub, but still cannot write even a somewhat complex code structure. Perhaps because GitHub is filled with far-from-perfect code, 90% of which consists of examples from people learning technologies, and copied homework from each other, inheriting errors in them.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Therefore, for now, we can only talk about supplementing the development and testing process. And many companies in 2023 will be looking for optimal applications of such supplements. This will definitely continue into 2024.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"AI Augmented Testing\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Just as AR (Augmented Reality) occupies a space between the Real World and the Virtual (VR), so we're entering an intermediary stage between traditional testing and full-fledged testing with AI, which we'll call AI Augmented Testing. We'll inhabit this era until the advent of General AI or something closely resembling it.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"AI Augmented Testing could take various forms: from generating BDD scenarios based on existing keyword libraries or searching for the most similar test scenarios based on their steps, to generating templates for unit or API tests for any API in your application.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This will manifest itself in the emergence of both scripts and algorithms for local application, as well as extensions for code editors (IDEs). Even within our company, we've identified over 700 valuable applications of GPT-like models, sifted from a total of several thousand. The same process will undoubtedly be happening in other companies.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Are we just entering this phase? Far from it. We're already deep in it. Visual Testing with image recognition, like in \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://applitools.com/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Applitools\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", self-healing capabilities for Selenium-based test cases, like in \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://healenium.io/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Healenium\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", and the analysis and categorization of test results, like in \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/?utm_source=trigger&utm_medium=rp_1&utm_campaign=trends&utm_content=blog\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" - all of these are already here. Now they're receiving a new stimulus and renewed interest.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The trend for 2023-2024 will be the creation of accelerators capable of incorporating these AI Augmented Capabilities. The foundation for them should be platforms that cover the maximum testing or development workflow. Alternatively, this may lead to an increasing number of accelerators being compelled to amalgamate their abilities into a unified platform.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Data Privacy and Security\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Data protection is becoming even more critical. Some companies have globally prohibited the use of ChatGPT and its analogs due to concerns about data leaks or training models on company achievements. Therefore, local models like DaVinci and BERT will increasingly come into play.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The cost of these local models and the amount of data required for their training will likely be limiting factors. Thus, solutions that can serve as interfaces for any model, allowing the end user to choose which provides the best results, will take the lead.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Switching between local models and those from cloud providers will help achieve maximum results. 2023 and 2024 are set to be years of intensified development for local versions of these models, with a heightened focus on security.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Platform-centric Solutions\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Increasingly, market solutions and tools will move from niche solutions to horizontally expanding their capabilities. We're already seeing this with tools like SauceLabs and BrowserStack. These systems, initially providing access to remote browsers, are gradually broadening their scope through the addition of tools for performance, test result management, observability, test case management, visual testing, and more.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In the trends of 2023-2025, we likely anticipate a return to systems on the scale of HP ALM, but enriched with smarter features than before, augmented with AI. This could manifest in active company acquisitions or horizontal functionality growth.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"More SaaS and Less On-Prem\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Cloud solutions and services are permeating the development process more deeply, gaining trust from even the most conservative market players, such as banks and financial institutions. Development and system engineering, i.e., Dev and Ops, have almost entirely migrated to cloud services. It's now time for the Test part to follow suit and complete the DevTestOps cycle.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This trend will be strongly supported by the \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.linkedin.com/posts/ghdmitry_ai-testing-software-activity-7050208879938281472-hChI/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Containerization Revolution I've written about previously\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". We've already learned to containerize production applications and we're doing quite well at containerizing development and testing environments. The next step is working with remote environments, which will, of course, be part of the SaaS infrastructure.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The trend for 2023-2024 will be an increased transition to SaaS systems, starting from Test Case Management systems to the execution of automated tests, use of remote infrastructure, test generation, result collection, and verification. Your computer will increasingly become a \\\"window\\\" into a large development infrastructure where you'll be writing some code executed somewhere in the cloud. And soon, you'll just be watching how this code is written by an AI algorithm and executed somewhere out there.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"JavaScript vs Programming Languages\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The trend for 2023-2024 will definitely be the continued exponential growth of test automation in JavaScript. Python is battling for the second position of steady growth, leaving JVM-based languages (Java, Kotlin, etc.) behind.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Based on the statistics from ReportPortal and the execution of tests involving our agents, we're witnessing the rapid growth of JS. This doesn't mean that Java automation has surrendered its position, not at all. Considering the age of this technology and the volume of existing automation in Java, it will remain in the top tier and even continue to grow for quite some time. However, the growth of JS-based automation is impressive.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In general, this is good news for the JS automation community, especially for \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://playwright.dev/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Playwright\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". However, it's bad news for \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.cypress.io/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Cypress\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". Huge investments in marketing once allowed it to build its audience, but we're seeing interest in Cypress wane. Our suspicions are confirmed by \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.reddit.com/r/softwaretesting/comments/12ii8ib/cypressio_is_about_to_die_you_should_migrate_your/?rdt=46031\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"discussions in the Reddit community\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". It seems we're observing a \\\"sunset\\\".\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Consolidation and Persistence of Test Reporting\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Starting in 2021, projects have increasingly started to consider consolidated storage of testing results. This is especially considering the variety of test types, testing frameworks for their implementation, and even programming languages.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In 2023, the necessity and ability to gather all testing results together to make informed decisions becomes even more critical. Yes, the world at large, and testing in particular, will have a tough time fighting against the flood of Excel reports from team leaders. But in an era of increasingly cloud-based infrastructure and GitLab pipelines that don't leave behind artifacts, the ability to save results in real-time becomes more and more relevant.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/?utm_source=trigger&utm_medium=rp_2&utm_campaign=trends&utm_content=blog\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" has been addressing this capability for quite some time now. I'm reminded of questions at conferences about 5 years ago along the lines of \\\"Why do we need this?\\\" - now it's not just a possibility, it's a necessity. And we were able to catch this trend in time.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Quality Gates\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Starting in 2021, the possibility of creating automated Quality Gates has become increasingly relevant.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Imagine you've learned to gather all testing results at a single point, you've managed to conduct a complete analysis of failures and categorize their causes using ML algorithms, you have information about which components, flows, and priority parts have been tested, and now you'd like the ability to make an automatic decision on whether your application is ready to move further along the pipeline after the testing stage or not.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This is precisely what the concept of Quality Gates is for, which provides the ability to create complex rules for decision-making. For example, we don't want to have test failures for critical functionality, we don't accept product problems in functionality related to payment, but we're ready to pass the build if we have, for example, failures in test cases with minor priority and even more so if they failed due to test irrelevance.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"A premium feature called Quality Gates in ReportPortal allows you to achieve exactly this and provide the simplest Go/NO-GO answer back into your pipeline.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The trend for 2023-2024 will be the widespread adaptation of Quality Gates on top of the results of automated testing.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Shift-Left Testing\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"More and more major companies in the market are focusing on shift-left testing approaches. Namely, they're making testing tasks increasingly the responsibility of developers. Yes, there's still a need for specialized knowledge about the domain or specific testing conditions, which the testing team covers. But overall, there's a noticeable trend of moving automated testing closer to developers. What does this give companies? Primarily, it reduces expenses while improving product quality.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"How can one increase quality while decreasing testing costs? The answer is quite simple - it involves breaking down silos in the development team's thinking, where the mindset is \\\"I've done my task, tossed it over the fence to testing, and it's no longer my concern.\\\" When the responsibility for quality becomes part of the developer's tasks, it changes attitudes towards how testable the code is and how resistant it is to exceptions and corner cases.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"One could argue that this slows down the team's velocity. And that's true. However, at the same time, it reduces the team cost for the testing and automation team. By changing the team composition, we can simply increase the number of developers on the team to maintain velocity.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"So, how do we save money then? If we've merely shifted costs from one team to another? The savings here occur due to accelerating the bug resolution cycle in the product. At the very least, there are fewer bugs, and at most, they're discovered faster at earlier stages, which also speeds up time to market.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In-Sprint Test Automation\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Emerging from the shift-left movement, in-sprint automation will gain more attention and interest as it will be a crucial and the most beneficial way to achieve a Shift-Left approach.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"Trends in automated testing in 2023"},"leadParagraph":{"leadParagraph":"It's undeniable that the emergence of ChatGPT has rocked the entire world and all industries, particularly software development and testing. Large Language Models (LLMs) have been around for a while, but the implementation of such a generative version of an LLM model in a chat format, which maintain"},"category":["Test Automation Trends"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/3avlxQRB1mKpDmmeyhgVJX/b796046faa972850afddb9a80d4201ff/trends.svg"}}},{"id":"82a36612-3c87-5e0a-b072-5cefd32d7aad","slug":"new-approach-to-versions-naming","date":"May 18th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Our team aims to release often and provide more flexibility for our users and ReportPortal team itself in feature implementation and delivery. Our priority is always to deliver the product to our users as soon as we can (without sacrificing the product quality). That gives us an opportunity to collect users' feedback earlier and adjust our development strategy following your needs and market trends.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Based on the above, we decided to review our versioning models and release flow and move toward the new ones:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Semi annual product releases\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Regular service release\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"ordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The previous approach to versioning\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Previously we used the approach to versions when the services were updated dependently. For example, if there were changes in the API service, Auth service and UI service that are not related to each other, we still made a release of these services trying to link them with a common version. Using this approach, we tried to understand in advance in which service and ReportPortal version the next changes will occur. We always synchronized all our components by the biggest change.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"With this approach, we often had to reschedule some features release when they were almost ready, but suddenly we urgently needed to update some component. Synchronization of services was causing problems, was painful and hard for the development process.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"So, we decided to change the approach to versions. Now we have replaced the Product release approach into separate Product release and Service release.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The main difference of a new approach\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"With the new approach, all our components (API Service, Auth Service, UI Service, Analyzer Service, Job Service) will have their own independent versions. We refused to synchronize versions. For example, if the API Service has major changes at the release time, and the UI Service and Analyzer Service have minor or patch changes, then their versions will be different. In addition, if there is no connection between their changes, we can release them separately upon readiness.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Product release\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Product release will contain a set of new features and a set of different ReportPortal services’ versions. At the very beginning of Product delivery planning, we don’t know what versions of the components will be included in the next release.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We use \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://calver.org/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Calendar Versioning\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" for Product releases. So, Product releases have the following pattern: yy.minor.micro(optional)-build, e.g., 2023.1 or 2023.2.5-768.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Service release\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Now we can release services separately from a Product release. Each service is independent of other services and has individual release and versioning. One important thing is to provide backward compatibility.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We use \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://semver.org/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Semantic versioning\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" for Service release.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"New approach to versions allows us to make fast implementation, testing, and delivery of new features to our users as well as collect and incorporate users feedback in our product. Besides functional changes this approach will allow us to release non-functional changes like security fixes in base image or dependencies more easily.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"New approach to versions naming"},"leadParagraph":{"leadParagraph":"Our team aims to release often and provide more flexibility for our users and ReportPortal team itself in feature implementation and delivery."},"category":["Delivery"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/6b5OGuNqI2tEtUG4RKib8X/3474e52252c47a470c2177893c6f3931/cvs.svg"}}},{"id":"f4310872-4262-54c6-b864-3c4add2fccc2","slug":"How-we-use-AI","date":"April 13th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Over the last few years Artificial Intelligence (AI) has been changing the testing process in many ways. Robots are programmed to think. What is more, they do tasks at high speed and with accuracy, and they don’t get bored with it.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Let’s see how ReportPortal uses AI power for the key features: Analyzer, Unique errors, Machine Learning (ML) suggestions, Quality Gates.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"AI for shift-left testing\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"According to the shift-left testing approach, you should run automation tests regularly so that you understand what is happening as quickly as possible. For example, you can run a daily regression to check what happened to a product after a new code merge. Accordingly, with many runs, it will take a lot of time to analyze the test results. This is where AI comes to the rescue. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can train Analyzer, and then it will take a part of your test failure analysis routine work and set a defect type, a link to Bug Tracking System (BTS) (in case it exists), comment (in case it exists). How does it work? We can mark 1 of the bugs as a System Issue in 10 Launches and put it as a Product Bug in Launch 11. So, the Analyzer will mark this issue as a Product Bug the next time it is started. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4YZgzTB3XHZ8ZGvfASMErg\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Note:\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" The total count of tests should be the same every time for a specific Launch. Don’t skip the tests.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"If Auto-Analysis didn’t define any failures, you can open “Make decision” modal and see ML Suggestion for this item. AI will tell you that the error log is very similar to another log. You can compare these logs and apply the defect type from ML suggestion or set it manually. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"2ed74I1V5KBhOa5PcSK63L\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"One more feature with AI-based defects triage is Unique Errors. The system automatically groups tests by the same errors: when you expand some error log, you see a list of steps where it occurred. It is very convenient when preliminary work has already been done instead of you. Thus, you can select these grouped by AI items and apply a defect type for them using bulk operation. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5yF6HMsAJGNHZxN5AGy3Ti\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"AI for CI/CD pipepline\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal speeds up a CI/CD pipeline thanks to Quality Gates feature, which has AI-driven “New errors” rule. In what situation can it be useful? Suppose you have already identified some errors, and they are minor, and you can go to release with them, and there is one more build to test. If you care about new unique bugs, you can create Quality Gate with “New errors” rule which works in conjunction with the Unique Errors functionality. Quality Gate will fail if a new defect is detected.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"“Amount of issues” Quality Gate rule is relevant to AI as well because Quality Gate with this rule is running after finish of Auto-Analysis. For example, if you have the rule “fail Quality Gate if there is at least 1 Product Bug”, and Auto-Analysis happens and marks an issue as Product Bug, then Quality Gate fails. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"7mbH9de0z31yw9704yO6Zj\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Overall, thanks to AI, you can get a test execution report and evaluate product health without any clicks. This magic process step by step:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Auto-Analysis is ON.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Quality Gates functionality is ON.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Integration with Jenkins is configured.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Launch is finished.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Auto-Analysis performs automated defect triaging and sets defect types.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal assesses Launch quality using the created Quality Gates rules.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal sends auto feedback to CI/CD tool with status Passed or Failed.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Based on ReportPortal feedback, CI/CD tool fails a build or promotes it to the next stage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"ordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"AI enhances the value of ReportPortal by saving your time and resources on automation tests results analysis (consequently – reducing costs). AI highlights areas that require more testing and attention. This can help stakeholders quickly understand the quality of the product and make informed decisions.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"How we use AI"},"leadParagraph":{"leadParagraph":"Over the last few years Artificial Intelligence (AI) has been changing the testing process in many ways. Robots are programmed to think. What is more, they do tasks at high speed and with accuracy, and they don’t get bored with it."},"category":["AI"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4cbBtkShqpz0ixbNtoJNkr/91e23f61064b0d615f99d65fa64a04f0/technology.svg"}}},{"id":"0b2d47a4-9a4a-5321-a1a1-2b58b216c283","slug":"Tips-to-get-ReportPortal-benefits","date":"February 13th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal is a one-stop solution to manage all your automation results and reports in one place. In this article our QA engineers shared their advice on how to use all ReportPortal capabilities to reduce test results analysis efforts and get pure visibility about product's health. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"1. Use hierarchy in tests\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can run your tests on the Launch level only. But in this way, it's hard to understand what they refer to. Because all of them will have the same type.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Our advice is to use the next hierarchy in your tests in ReportPortal: Launch – Suite – Test – Step. For example, you can distribute your tests by areas using Suite level. Thus, it will be easy to recognize what functionality the failed tests belong to.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5XvIGCXKEv1kPG4c6OoXfL\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"2. Use Test Case ID attribute\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The best way to distinguish test cases one from another is a Test CaseID. This is a fundamental attribute for the test case history and re-tries. If there is no Test CaseID defined explicitly the ReportPortal agent will generate it based on Code-Reference and parameters.\\n\\r\\nExplicitly Test Case ID can be added programmatically in code, via attributes: \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://github.com/reportportal/client-java/wiki/Test-case-ID\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"TestCaseID\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\".\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"3. Choose the relevant Launch name \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"If you are running different types of tests (Unit, API, UI), specify this in the Launch name. Thus, it will be clear for the whole team: what is this Launch used for?  \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"4. Use attributes properly\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can describe the environment or version using attributes. What is more, you can filter test executions by these attributes. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Sometimes users define the owner of the launch via attributes as well. But we recommend another way: when running tests, use the Access token of the person who is responsible for this launch (it can be copied from the Profile page in ReportPortal). So, the specified user's name will be displayed as the owner. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"54cLIdQIrSoNnFn7o7DdLg\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"5. Configure reporting tests via CI/CD\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can run tests locally. But the best practice is reporting tests to ReportPortal via CI/CD pipeline (for example, Jenkins). \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This way the whole team can run tests and view the results. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"6. Search for the similar \\\"To investigate\\\" items \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Most often you can see several \\\"To investigate\\\" items when reviewing the test results of the first run in ReportPortal. There are a few tips to make the analysis easier. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Open \\\"Make Decision\\\" modal for an item with \\\"To investigate\\\", wait for \\\"Apply for...\\\" section to be fully displayed. Now you can see all \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/analysis/SearchForTheSimilarToInvestigateItems/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"the similar \\\"To investigate\\\" items\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". You can select all identical failures and perform the bulk operation for them. It speeds up test results analysis noticeably.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"7BR8bFmfXdCmjEF5ozEEkd\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"7. Use Analyzer and ML suggestions \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can delegate a part of the routine duties to the Analyzer. For example, you have 100+ failed tests. You can open every test and explore every test log to find the reason for failure. But it will take a long time. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"As an alternative, you can run \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/analysis/AutoAnalysisOfLaunches\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Auto-Analysis\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". Analyzer will find all known issues and will link corresponding defects based on your previous investigation results. After that, you only have to check (like a controller) whether everything was found by Analyzer.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"rYHnLnXGJj4w0GzU2rp1A\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"If there are still some \\\"To investigate\\\" items left, just open \\\"Make Decision\\\" modal and look at the ML Suggestions. This functionality suggests the best options to categorize issues. It is a real time-saver for testers. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Note: Auto-Analysis and ML suggestions are useful in subsequent runs only after you do manual analysis in the first runs.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5jVohved4Ovjvi5XiE1r6Z\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"8. Use Unique Errors Analysis\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"One more feature to facilitate tests results analysis is \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/analysis/UniqueErrorAnalysis/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\\"Unique Errors\\\"\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Let’s imagine, you have 20 failures. Click on the Launch name and open the \\\"Unique Errors\\\" tab. Here you will find common errors for several failures. So, you can see 8 errors instead of 20, for example. Expand an error to check what tests belong to the same one. Then you can select some items and apply defect type/link issue/post issue for them via bulk update. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4Oq9r9Zr5yqVaRXHpMf9fC\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"9. Integrate ReportPortal with BTS\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Thanks to the integration with Bug Tracking Systems (Jira Server, Jira Cloud, Azure DevOps BTS, Rally) you will spend time once – when creating an issue.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Thanks to the integration with Bug Tracking Systems (\",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/plugins/AtlassianJiraServer\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Jira Server\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/plugins/AtlassianJiraCloud\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Jira Cloud\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/plugins/AzureDevOpsBTS/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Azure DevOps BTS\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/plugins/Rally/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Rally\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\") you will spend time once – when creating an issue.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1hATc39IU099Ml5x11N8Al\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"10. Use custom defect types\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"There are 4 main defect types in ReportPortal: Product Bug, Automation Bug, System Issue, and there is also \\\"No Defect \\\" group. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Custom defect types help to identify the most problematic area. For example, you have 5 Product Bugs, and you can specify each of them by functionality.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Another case: you can create \\\"Manually Passed\\\" defect type under \\\"No Defect \\\" group if the test is passed manually. It will help not to affect the overall statistic of the run. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Benefits:\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" to simplify the analysis, add the “Under Investigation” custom defect type or create custom defect type with the assignee name (for example, “Issue for Rob”). So other team members won't spend time analyzing such tests. This is about how to work in a big team without spending time on direct tasks assignments. Use comments as well for additional information or clarification on the issue, to better understand its context and potential causes. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"48zlHdzgO3A4em1H1YFBK6\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"11. Send manual tests in ReportPortal \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"There is a possibility to send tests from QaSpace (Jira plugin) to ReportPortal. It allows to get manual tests results as well and include them in the statistics via widgets.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"To configure QaSpace with ReportPortal, copy Access Token from the profile on ReportPortal and use it as API Token for ReportPortal Configuration:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"17hBMtMXivk8d0p2qvr7ma\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Launches from QaSpace are displayed in ReportPortal like normal launches. The only difference is Test Steps are shown as a Log message.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5Gw2HlXuCESh2NCVfR9Xx8\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"12. Create widgets\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can create different widgets when all failures are investigated. Widgets show the application quality by area, component, environment on 1 Launch or several Launches. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can include manual tests from QaSpace in the widgets as well.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Widgets help to see the product's health. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The most popular widget is \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/dashboards-and-widgets/OverallStatistics/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\\"Overall Statistics\\\"\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\". You can use it (just by doing the screenshot or attaching a link to the dashboard in ReportPortal) in test results reports. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3LM4ZuBTG5pLXcd7xmm7O\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"13. Use notifications\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can apply custom rules with specific conditions to send a notification on percentage of failed items which is very useful and helps to avoid unnecessary pings in case of random failures.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4weZeL2N9tUV08JI7ZcQMp\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"14. Use Quality Gates \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Let’s imagine an ideal test run: no Product Bugs, the percent of failure for all tests is 0 %. Create a \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/category/quality-gates/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Quality Gate\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" with these rules. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"While the Quality Gate is running, ReportPortal verifies testing results against the required conditions. It prevents the code from moving forward if it doesn’t meet the criteria.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4epJe2J9HLNX9TUSGkVWxc\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We hope these tips will help you improve your interaction with ReportPortal and get maximum value for your testing team and the entire project. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"Tips to get ReportPortal benefits"},"leadParagraph":{"leadParagraph":"ReportPortal is a one-stop solution to manage all your automation results and reports in one place. In this article our QA engineers shared their advice on how to use all ReportPortal capabilities to reduce test results analysis efforts and get pure visibility about product's health. "},"category":["Best Practices"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/5nYxavPSP5Zvw9Mv9dKufl/1baafa70b037a6fd896f47689632d13e/insights.svg"}}},{"id":"6d2f5e2b-1e53-5bb9-a1c9-dfc5e41fb8c6","slug":"performance-improvements-in-5-7-3","date":"December 22nd, 2022","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The system capacity has increased up to 13% compared to version 5.7.2\\n\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We are glad to announce some performance optimizations in version 5.7.3.\\n\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We updated the libraries in the scope of fixing Spring Framework Remote Code Execution (RCE) Vulnerability (Spring4Shell). As a result, the system capacity (requests per second) was increased up to 13% on the small server type* compared to version 5.7.2 during performance testing.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"* it is a small server type from the recommended optimal Kubernetes cluster configuration (you can check it out \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/installation-steps/OptimalPerformanceHardwareSetup\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"here\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\").\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4OtiFoBv8fYe52yyMlYuep\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Benefits:\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" It helps to speed up your reporting on the same environment just because of the version upgrade.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Response time for building history and filtering at all levels has become at least 18% faster compared to version 5.7.2.\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"5.7.3 version also brings performance optimizations in the core operations. The optimizations make basic functionality (filtering at all levels and test history building) at least 18% faster compared to version 5.7.2.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6mdsA3SM2DtuQQhxxZ8nUB\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Benefits: \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"Test history and filters load faster compared to the previous version.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Check out the \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://reportportal.io/docs/category/releases\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Release notes\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" for the full list of what’s new in version 5.7.3.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"RabbitMQ version updates\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We updated the RabbitMQ version from 3.9.17 to 3.10.7 and faced less RAM and CPU usage of the RabbitMQ container under the high load (more than 1 million messages in the 20 queues total).\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"89UF4bzmja1XOf1En0mXQ\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"Xzwh2Ux20drHR7aof4elS\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1M0mXfDr6RSmt4bTAl4uhx\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"2bzHPKmrH73XLtxIvCo1Lk\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Benefits: \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"It helps to decrease RabbitMQ resource utilization even under high workloads in the same environment just because of the version upgrade.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Thus, thanks to performance improvements in version 5.7.3 you can speed up your reporting and decrease resources usage of the ReportPortal even under the high workload.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"With 5.7.3 version we are also addressing a huge list of security vulnerabilities. Please, see Release notes for details.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"Performance improvements in 5.7.3"},"leadParagraph":{"leadParagraph":"We are glad to announce some performance optimizations in version 5.7.3."},"category":["Performance improvements"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4SDH3jaisqRiD81N8maID9/e91e990f7514198f1f6a172dba1e23be/report.svg"}}},{"id":"b3f0b221-339c-5923-9bc6-a813f60237d9","slug":"double-entry-in-5.7.2","date":"September 5th, 2022","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The ReportPortal’s essence is based on assistance in working with automated testing results, and it all starts with the aggregation of results at a single place. For a long time, the relational database served well as a storage place for us. But the more test cases you run, the more storage you need to keep all related logs.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Before we introduced PostgreSQL with ReportPortal v5.0, we were using MongoDB from version 1 to version 4. MongoDB is a document-oriented non-relational database, was pretty good at writing the logs, but was a kind of nightmare to track metrics, build charts and find insights across testing results.  \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"PostgreSQL resolved data joins for us and made implementing new features much easier and quicker. But it also brought some drawbacks: such as excessive disk space usage to keep and rotate logs, slowdowns on data inserting, high CPU loads on data deletion and constant required maintenance (VACUUM clean).  \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"There are several reasons why \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://dba.stackexchange.com/questions/123627/postgresql-data-files-have-size-more-than-data-itself\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"PostgreSQL uses more disk space than the data itself\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", and it comes mainly from indexes of the data and several copies of the same data, due to specifics of PostgreSQL mechanics. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Logs are a big portion of data inside ReportPortal. And assuming specifics of the workflow associated with it, it should be constantly added and deleted, without much of the need to keep it for a long time. Even ReportPortal’s Machine Learning in Auto-Analysis feature will use it just several times for training and will store it transformed inside the ML model. But constant insertions and deletions will produce a significant load and innumerous storage footprint. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"By reconsidering all pros and cons, we made a deep investigation and performance analysis of ElasticSearch vs PostgreSQL from the perspective of ReportPortal’s load model and nature of data. The results of this investigation go below in this article.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Assuming these results, our architectural decision was to switch logs storage from PostgreSQL to ElasticSearch, well… because we already have it as a part of our application. And since it gives us such benefits as reduced storage footprint up to 8.5x times, and data deletion up to 29x times quicker with just a fraction of the CPU load.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"And also, it opens up the capabilities of the full-text search! \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Please read our findings below. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"LFPLPVbLZAJlAeZdSvaSR\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Why we use ElasticSearch?\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"PostgreSQL was previously used as a database for log storage, but – according to the performance tests – this is not the most effective way. Log messages take up the most space in the database, so we decided to transfer them to ElasticSearch. Logs migration to ElasticSearch will significantly reduce storage occupied by the log table. It will improve overall database performance (timings and costs of infrastructure). \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In version 5.8 ReportPortal will still rely on ElasticSearch v7.10, as the last available version under Apache 2.0 license. And going forward we will consider Elastic-like solutions and forks, but this will come into play after a series of performance analyses and investigations. So please stay tuned, we know that it could be an issue for some of our users, but in order to avoid hasty decisions we have to make it incrementally. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6kpNmWJbj2X4sWUNHEcxAa\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"What would you get with the ReportPortal v5.8 and the switch to the ElasticSearch logging? \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It’s not something that you will see at the first moment, but definitely will benefit you in the long run, with outcomes like: \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Reduced disk space usage, with a smaller footprint up to x8.5. \\r\\r\\n\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Reduced maintenance of the PostgreSQL database, and reduced requirements for the shape sizes by at least x2 times. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Reduction of database load used by pattern analysis up to 5x times. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Full-text search capabilities for text logs (x33 times quicker for text queries, and less CPU utilization 1 – 16x times in comparison with PostgreSQL). \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Similar performance with PostgreSQL on getting logs by ID. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Storing logs in different indices per project allows to get project data faster and reduces the risks of locks occurrence. \\n\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"ordered-list\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5aW4VdMh36McTltHdmsbSz\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg ElasticSearch is lower by storage up to \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"8.5x\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" times.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Why we use Data Streams?\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Elasticsearch provides a special approach for storing log data: “A data stream lets you store append-only time series data across multiple indices while giving you a single named resource for requests. Data Streams are well-suited for logs, events, metrics, and other continuously generated data,” – described in \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.elastic.co/guide/en/elasticsearch/reference/current/data-streams.html#data-streams\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"the official elastic search documentation\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\".\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Data Streams benefits \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Logs deletion by IDs is x29 times faster in data streams compared to Indices;\\r\\n\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Fast logs insertion (reporting) at the time of the high workload;\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Creation of cheap data nodes for old data, e.g., HDD with low resources. ElasticSearch allows configuring the old data storage using ILM (Index Lifetime Management) policy. It might be useful, for example, if your project uses some information once per week/month, etc;\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Various index rollover conditions – fast creation of the new generation. It means that a new generation of this data stream is created when the limit is reached (by logs count, by logs amount, by date). So, logs of this data stream proceed to the new generation. Limits can be specified in the IML policy per project;\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"ordered-list\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6pdFzkHaqEkH0gybR2T4aR\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Response times table (95pct)\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-4\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4c0jDiw0IcE9PMBhl0t2pU\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Deletion by IDs performance comparison\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-4\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"43NYyP0KjWRtem1b2XVpkC\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"29 times faster\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" in comparison with index, logs deletion by IDs from data streamers\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"29 times faster in comparison with index, logs deletion by IDs from data streamers \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://opster.com/guides/elasticsearch/data-architecture/elasticsearch-data-streams/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"here\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\"\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"What effort is required from users? \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We recommend updating to version 5.7.2 for a smooth transition of full logging to ElasticSearch, especially if you have many logs. If you update to version 5.7.2, use it for 3-4 months before version 5.8. This period will be enough for the vast majority of projects to generate enough logs history inside ElasticSearch. And then update to version 5.8 once it is available. Since all logs will already be stored in ElasticSearch, no efforts will be required to do the migration. Along with version 5.8 we will distribute a migration script and instructions for data migration so that you can easily migrate from the early 5.x version. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Note 1\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Before version 5.8, double logging might increase the resources usage – CPU, disk space. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"blockquote\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Note 2\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We are already using the ElasticSearch license, so, no new license is required. For now, we stay on version 7.10 with Apache 2.0. We might switch to OpenSearch in prospect.  \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"blockquote\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"To summarize, using of ElasticSearch and Data Streams will bring significant performance benefits in the future.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"ReportPortal moves test logs from PostgreSQL to Elastic-type engines"},"leadParagraph":{"leadParagraph":"The ReportPortal’s essence is based on assistance in working with automated testing results, and it all starts with the aggregation of results at a single place. For a long time, the relational database served well as a storage place for us. But the more test cases you run, the more storage you need"},"category":["Architecture"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/60v9RHeDDNhpHIpea8nQ7s/131355e1407215723c900968e54e6a27/database.svg"}}}]}},"pageContext":{}},"staticQueryHashes":["1800307753","3810076356"],"slicesMap":{}}