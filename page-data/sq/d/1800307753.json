{"data":{"allContentfulBlogPost":{"nodes":[{"id":"37584917-9729-5501-af19-4f5118a55c69","date":"October 17th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Nowadays, test automation is an essential part of the software development process. For effective test automation, it is crucial to build a QA metrics dashboard. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"But firstly, we have to complete some prerequisites.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\rPreconditions\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"1. Build a testing pyramid for the project. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Specify the number of tests at each level that are planned to be automated and those that are already automated to understand the coverage.\\n\\nFor example, we can have the following suggested groups: A, B, C.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"A - the most critical tests that we would like to automate with 80% coverage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"B - we work on these tests as a second priority, aiming for 60% coverage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"C - we expect 20% coverage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"unordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It is important to appropriately mark test cases in the project management tool (for example, Jira, Rally, Gitlab, Trello) - what is planned to be automated, and what is already ‘In progress’. \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"2. Add attributes to test cases. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can use attributes to specify the area to which the test cases belong to, for example, \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'component: UI'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\". Additionally, attributes can indicate the scope of these tests, such as \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'label: smoke'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\". In the attributes you can also specify the environment where the tests are run, as well as the branch, plugins, and third-party systems. When the same scope of test cases is executed against different environments, versions, or with different plugins, it is beneficial to indicate these differences in the attributes.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6JxigKYbkzoH5suIMsSThF\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"So, we have completed the preconditions, and now we are ready to create the test automation results dashboard. We recommend creating different dashboards for various purposes: for regression testing, for specific versions, for unstable tests, etc.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1lolQnY68IuB2PDbouJOVC\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In ReportPortal, you can track test automation metrics using our widgets.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Tracking Test Automation: ReportPortal‘s Top 5 Widgets\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Overall Statistics\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This is a summary of test cases with their statuses. In the test result report, you can only set Total/Passed/Failed/Skipped. Additionally, this widget shows the number of bugs categorized by defect type: Product bugs, Automation bugs, and System issues or custom defect types. The widget has clickable sections, allowing you to navigate and view test failures and their causes. Afterward, post an issue in the bug tracking system (BTS) for all Product and Automation bugs or link the already created tickets to the failed items in ReportPortal.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4ni9dNIqFOWdhuWUv3x5EK\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Unique Bugs Table \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This widget displays existing bugs created in the BTS. It enables us to track the issues within our product. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"2ybWGW8dyXbLEid1nzACpI\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Passing Rate Summary \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Initially, it is sufficient to understand the proportion of Passed/Failed cases.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Here, you need to pay attention to the failures: are there any tests that are constantly failing and that don’t yet have a defect type?\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4egJWwjKdLnoh1FZXi3m40\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Flaky test cases table \\r  \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The widget displays the most unstable tests.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It's not just a failure when we know, for example, that it's an automation bug. But if a test first passed, then failed, and then passed again, it means the issue is either in the test itself or in the environment. We need to investigate everything we see here.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3uHxxD6GW09TA6jIL1kshz\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Cumulative trend chart\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You only need to build it once to obtain launch summary statistics with one attribute. For example, if we have an \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'environment: dev'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" attribute, it's convenient to view statistics for this environment.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In the ReportPortal, there's a peculiar feature: if a launch has a certain attribute, and there are no attributes at the step level, then all tests within that launch are associated with that attribute.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Therefore, if we have an \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'environment: dev'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" attribute, the system treats all tests within that launch as if they also have this attribute. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4E7UzDHdqkjzOBI9U7Xvmf\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In summary, test automation metrics help to enhance test automation, and as a result, contribute to the creation of high-quality software.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"How to create a QA metrics dashboard in ReportPortal"},"leadParagraph":{"leadParagraph":"Nowadays, test automation is an essential part of the software development process. For effective test automation, it is crucial to build a QA metrics dashboard. \n\nBut firstly, we have to complete some prerequisites."},"category":["Best Practices"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4BXb5XyjHaWoKZDWt78h6n/42688cc418cd33231ce60a5ff154ce6f/metrics.svg"}},"slug":"how-to-create-a-qa-metrics-dashboard-in-reportportal"},{"id":"14d869b2-fd5b-5439-aa55-0ce0022eb505","date":"September 16th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We would like to highlight that in version 5.7.5 of API Service and Authorization Service we have updated the dependencies.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Unfortunately, the same dependency found its way into different versions, causing a Java error that looks like this: \\\"AuthUtils$SerialUidReplacingInputStream: Potentially Fatal Deserialization Operation\\\" when serializing/deserializing a user class or token.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Example of a stack trace from logs:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"blueBg \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"AuthUtils$SerialUidReplacingInputStream : Potentially Fatal Deserialization Operation.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"\\r\\n\\r\\njava.io.InvalidClassException: Overriding serialized class version mismatch: local serialVersionUID = 550 stream serialVersionUID = 520 \\r\\nat com.epam.ta.reportportal.auth.util.AuthUtils$SerialUidReplacingInputStream.readClassDescriptor(AuthUtils.java:105) \\r\\nat java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1992) \\r\\nat java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1870) \\r\\nat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2201) \\r\\nat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687) \\r\\nat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489) \\r\\nat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447) \\r\\nat java.base/java.util.TreeSet.readObject(TreeSet.java:524) \\r\\nat java.base/jdk.internal.reflect.GeneratedMethodAccessor226.invoke(Unknown Source) \\r\\nat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Everything is functioning well; however, since users are verified for all requests, including reporting, many errors are filling up the Service API log. To prevent this log from excessively cluttering the Docker, additional logging rules need to be configured in Docker's configuration.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We recommend using the following settings in the Docker compose file for the ReportPortal services containers:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"5IaEMQgny0x2KzRGQnZaC6\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"blockquote\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Note 1\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This is a default recommendation from Docker, and you may need to adjust it to fit your project's specific requirements.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"If your installation is via Kubernetes, you don't need to worry about log rotation because Kubernetes already has it configured by default. However, Docker doesn't have log rotation enabled by default, and its JSON log format can quickly consume all available space.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We plan to update Docker compose in the future, so these log settings will be included in the compose file automatically. Until then, if you are using version 5.7.5 or 23.1 with Docker installed, please check how much space the logs are occupying and update the Docker compose file accordingly.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Default paths for checking logs: \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Linux:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" /var/lib/docker/containers/ \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Windows:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" path depends on the way you’ve installed Docker. Please, check \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://docs.docker.com/desktop/troubleshoot/overview/#check-the-logs\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Docker documentation\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\".\\r\\r\\n\\r\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]}"},"title":{"title":"Deserialization issue workaround"},"leadParagraph":{"leadParagraph":"We would like to highlight that in version 5.7.5 of API Service and Authorization Service we have updated the dependencies. Unfortunately, the same dependency found its way into different versions, causing a Java error when serializing/deserializing a user class or token. How can this be fixed?"},"category":["Product"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/3DHvdns0eyniI6qPnrckE3/b24dc5f1ce7668dbc16f65ac36445d3f/Deserialization.svg"}},"slug":"Deserialization-issue-workaround"},{"id":"581a785f-a448-5d49-8c9a-5cac42dd4dda","date":"August 9th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The main goal of CI/CD is to reduce lead time. This is an important metric that shows how quickly a new feature goes into production. With perfect CI, this process can take just a few minutes. What do we need to deliver features with such speed? Here are some recommendations from the EPAM Test Automation community Mikalai Biazruchka, Oleksandr Halichenko, Yauhen Klimiashuk, Dzmitry Prakapuk. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Define a Git branching strategy and environment strategy \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Continuous Delivery/Deployment is the process of validating and delivering a product to pre-production and production environments. This process goes through the available environments. Git branching strategy and environment strategy are interrelated and define the product build process – from which branch to which environment. If the Git branching strategy and environment strategy are not coordinated, then, accordingly, the process of delivering the product to pre-production and production will not be transparent and may exclude the possibility of building a CI/CD process. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Define quality gates \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A quality gate is a set of step-by-step quality checks that help determine if we can proceed to the next stage or not. Examples of quality gates in development include code review, different linters, vulnerability detection via Sonar, and unit tests. Examples of quality gates in automation include smoke tests, running all tests, or some tests on changed objects. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"By the way, \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://reportportal.io/\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"ReportPortal\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\", as a continuous testing platform, has a premium \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://reportportal.io/docs/quality-gates/QualityGatePurpose/\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Quality Gates feature\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\".\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Choose the right CI tool \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The best option would be the tool that comes with the code repository: GitHub Actions for GitHub, Azure Pipelines for Azure DevOps, and GitLab CI for GitLab. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Implement CI/CD as soon as possible \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Ideally, after every developer’s commit, the entire range of checks should be started: static code analysis, unit tests, code style analysis, integration tests, and end-to-end tests, including UI and API. These checks are aimed at building a Continuous Delivery process where we not only collect (integrate) everything but also deploy somewhere or provide artifacts, such as docker images. In the ideal world, each commit should turn into a new deployment to production. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Learn the toolset of the platform you are working with \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Each platform has its own set of commands and tools that are used for CI/CD-specific purposes. It happens that those who work, for example, on .NET do not know the Command-line interface (CLI) very well. Accordingly, a person who does not know the CLI will not be able to create a full-fledged CI process for the platform in question. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use static code analysis\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Each platform has its tools to evaluate code quality. You should not only install them but also pay attention to what they offer because this provides serious feedback that will help to improve the quality of the code and prevent serious errors. These tools are easy to set up and take little time, but their value is significant. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Consider the pipeline's execution time \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Developers expect the CI pipeline to run in less than 30 minutes. This is the best practice now. If the pipeline takes longer, you need to think about how to fix it. This is where caching can help. It speeds up the CI pipeline a lot since we don't have to rebuild dependencies. On the other hand, caching introduces a certain element of instability because the cache may be invalid or outdated, which can lead to unexpected crashes. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use parallel jobs \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Using parallel CI/CD jobs increases productivity. If you can parallelize specific steps without losing the validity of the pipeline's feedback, then it always makes sense to do that. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use detailed logging\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Additional logging helps not only with the development of the CI/CD pipeline but also with its maintenance. When something goes wrong, having granularly split steps inside CI/CD and the correct logging makes finding a problem in the pipeline much easier. It becomes easier to understand what is happening and how it is happening. For example, if we produce some artifact, it would be nice to properly name it so that it is clear what it is, why it is needed, and where it came from. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use a pipeline-as-code approach \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The recommended approach is to create the pipeline in YAML format or the form of JSON or some kind of executable script: it is located next to the code; it is easy for versioning and easy to change. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Inexperienced engineers often use a graphical interface to create a pipeline. This works well, but when something needs to be changed, questions arise: who changed it, what was changed, and when. Besides, if something went wrong after some change, it is problematic to find this change and revert it. Nowadays, almost all major platforms support the pipeline-as-code format, which allows you to write pipelines in text form. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"It may seem difficult at the beginning of using this approach. But once you get comfortable with the syntax, it gives you more flexibility, and becomes more robust. If you need to transfer the pipeline from one project to another, then it will be just copying the file. If a graphical interface is used, it will most likely need to be recreated from scratch, where something can be forgotten, lost or overlooked. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Collaborate with the development team \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Automation should be in cooperation with the development team. Then, it will be possible to build an effective delivery process and avoid gray areas. It is necessary so that the development team can always indicate what should be paid attention to. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Optimize the test set for each stage \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Automate as much as possible but define clear timelines for each stage (sanity – on push, smoke – daily, regression – every week, etc.). Generally, test design is very important to have a well-established CI/CD process. Poorly prepared tests can take a long time to run or check the wrong thing. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Optimize version control system (VCS) flows \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Minimize branching to avoid high efforts on the code merge process. Encourage teams to merge frequently to avoid lots of branches per engineer. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Keep a stable infrastructure for testing \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"It is great when autotests are integrated into the CI/CD pipeline, and at the same time, it is important that the tests run quickly, and the results don't depend on the infrastructure. For example, if we have 8 threads but only 5 browsers available, then use cloud providers (BrowserStack, Mobitru, SauceLabs) to speed up your test execution via parallel execution. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use centralized test reporting tools \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Test automation reporting tools have enough capabilities to analyze test results and provide clear reports to the stakeholders. It is very convenient to have everything in one place and allows you to get the green light earlier. This is also evidence that the Continuous Delivery process is effective. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"By following these tips, you can build effective CI/CD, streamline the development process, and improve software quality. \",\"marks\":[],\"data\":{}}]}]}"},"title":{"title":"Tips and tricks for successful CI/CD"},"leadParagraph":{"leadParagraph":"The main goal of CI/CD is to reduce lead time. This is an important metric that shows how quickly a new feature goes into production. With perfect CI, this process can take just a few minutes. What do we need to deliver features with such speed?"},"category":["Best Practices"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/2oHVDlJakMfnbuLu3VlPe0/59ff51e65b7b15b2d901f461b40d7841/CICD.svg"}},"slug":"tips-and-tricks-for-successful-ci-cd"}]}}}