{"data":{"allContentfulBlogPost":{"nodes":[{"id":"7e0cf4b3-af8b-561e-8707-dda2d9ccaa71","date":"February 27th, 2024","author":"ReportPortal Team","articleBody":{"raw":"{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We are pleased to announce that ReportPortal has successfully completed a SOC 2 Type II audit performed by Deloitte Auditing and Consulting Ltd. We have confirmed that we accurately, comprehensively, and thoroughly control many aspects related to the provision of our service and the development of our product. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\\rThe examination was conducted throughout the period from May 1, 2023, to October 31, 2023. Deloitte performed the engagement in accordance with SOC 2, a compliance standard for service organizations developed by the American Institute of CPAs (AICPA). This standard is based on the following Trust Services Criteria: \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Security, Availability, Processing Integrity, Confidentiality, and Privacy\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\". Meeting SOC 2 requirements indicates that an organization maintains a high level of information security. Customers often require SOC 2 compliance from organizations, especially when choosing a SaaS provider, to ensure their data is protected. As part of the SOC 2 certification scope, our SAAS service was audited.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"5rH8qLhsRP2aaWtVCccTE5\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Deloitte noted that ReportPortal, as a part of EPAM Global, has:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\\rA \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Corporate Internal Audit Function\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\", with Internal Auditing as an independent function aimed at enhancing risk management and operations.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"EPAM’s Process Asset Management\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\", ensuring administrative and operational controls for each major functional area are documented in various policies, standards, and process descriptions.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Risk Assessment and Business Impact Analysis\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" procedures, integrating risk management into its operations via strategies such as annual security risk assessments and a Business Continuity Program to protect corporate assets and maintain service levels.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Operational Monitoring\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\", where exceptions in normal or scheduled processing due to hardware, software, or procedural problems are logged, reported, and resolved daily, with appropriate levels of management reviewing these reports and taking action as necessary.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Client Account Monitoring\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\", wherein each client is assigned to a Customer Success Manager who communicates regularly to discuss issues and client satisfaction.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"As a result of certification, Deloitte released SOC 2 and SOC 3 reports that you can request \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://reportportal.io/contact-us/general\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"here\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\".\\r\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Moving forward, we plan to go through this procedure annually to ensure we are doing everything correctly, with quality and proper control, to provide our clients with the best service.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"About ReportPortal\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\\r\\nReportPortal is an open-source solution that provides a test automation reporting dashboard, ensuring transparency and efficiency across the DevTestOps pipeline. This comprehensive tool simplifies the test automation process and quickly identifies weak areas. It lowers costs and integrates seamlessly with the most popular frameworks, all powered by a real-time dashboard.\\r\\r\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Using ML, ReportPortal analyzes test outcomes, pinpoints the causes of failures, and assists in the defect triage process. As a SaaS, it minimizes the challenges of deployment and maintenance, while delivering all advantages of the product, efficaciously showcasing product readiness to management teams.\",\"marks\":[],\"data\":{}}]}]}"},"title":{"title":"ReportPortal completes SOC 2 Type II audit"},"leadParagraph":{"leadParagraph":"We are pleased to announce that ReportPortal has successfully completed a SOC 2 Type II audit performed by Deloitte Auditing and Consulting Ltd. "},"category":["Product"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4pRucyuhjD3S1x7dDWtS40/6c1e4cc062e0e87d604f78f26a3f0911/Property_1_SOC2.svg"}},"slug":"reportportal-completes-soc-2-type-ii-audit"},{"id":"197bd3c7-8718-5202-b4b4-e7f87bbd711d","date":"November 21st, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Flaky tests are the wild cards in the software testing world. Flaky tests happen when a test often changes its status from passed to failed and vice versa under the same conditions. Flaky tests can cause a lot of delays, questions, and chaos for software developers and QA teams.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Flaky test cases table widget \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"ReportPortal allows to find flaky tests in your runs. For that, create a Flaky test cases table widget in our test automation results dashboard: specify the Launch name and the Launches count for comparison.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"blueBg The widget is built by the name of the launch, and not by the filter. To obtain all the data in this widget, make sure that the launches in which you want to address flaky tests have the same name.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Flaky test cases table widget shows the 50 most unstable test cases in the selected launches. This includes not only Failed tests but also tests that change their status from Passed to Failed, from Failed to Passed. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This widget is dynamic, it only needs to be built once, and it will update automatically.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6wnzPPQQjr0Mj5OFxl3u9G\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"When creating the widget, we can also specify whether to include Before and After methods. Before and After methods are preconditions/postconditions, for example, creating test data, and then, after running the tests, cleaning them up. The reason for flakiness is not always within the test itself – the methods can also be flaky. For instance, the test itself might fail if generating test data fails. In the Launch, the reporting may be fine, and the test case would have passed if the Before or After method was functioning correctly.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Therefore, when a certain number of runs have accumulated, especially in the case of large launches, it is challenging to analyze failed automated tests. You can create this widget, investigate the unstable tests, and understand if there is an issue with the Before/After methods. The problem may not be in functionality, but in automation. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Additionally, with the flaky test widget, you can identify issues with the environment or with a specific version or branch. For example, if a test runs on different environments and passes in some, fails in others, you can temporarily remove these tests from the scope until the environment-related issue is resolved, saving time on running and analyzing flaky tests.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"How to avoid flaky tests?\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\nFor those seeking ways to prevent flaky tests, consider the following best practices:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Stable Test Environment\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Check the availability of critical resources for test execution. Control external factors (e.g., system resources, network connectivity).\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Test Isolation\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Decrease the number of connections between tests. It can significantly minimize the risk of instability.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Optimal Test Timing\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Properly plan your tests to ensure optimal performance for your testing environment. Remember about network congestion and system load.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Test Data Management\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Do not use mutable or shared data that can cause flakiness.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Overall, if you know what causes flaky tests and apply best practices to prevent them, you can reduce the impact of flaky tests. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"Flaky test: best prevention practices"},"leadParagraph":{"leadParagraph":"Flaky tests are the wild cards in the software testing world. Flaky tests happen when a test often changes its status from passed to failed and vice versa under the same conditions."},"category":["Best Practices"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4eQDfyCFkL2RPwYbGorwjN/f8c1371ff85238ec12c9636e7ce82110/Flaky.svg"}},"slug":"flaky-test-best-prevention-practices"},{"id":"37584917-9729-5501-af19-4f5118a55c69","date":"October 27th, 2023","author":"ReportPortal Team","articleBody":{"raw":"{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Nowadays, test automation is an essential part of the software development process. For effective test automation, it is crucial to build a QA metrics dashboard. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"But firstly, we have to complete some prerequisites.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\rPreconditions\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"1. Build a testing pyramid for the project. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Specify the number of tests at each level that are planned to be automated and those that are already automated to understand the coverage.\\n\\nFor example, we can have the following suggested groups: A, B, C.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"A - the most critical tests that we would like to automate with 80% coverage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"B - we work on these tests as a second priority, aiming for 60% coverage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"C - we expect 20% coverage.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"unordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It is important to appropriately mark test cases in the project management tool (for example, Jira, Rally, Gitlab, Trello) - what is planned to be automated, and what is already ‘In progress’. \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"2. Add attributes to test cases. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can use attributes to specify the area to which the test cases belong to, for example, \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'component: UI'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\". Additionally, attributes can indicate the scope of these tests, such as \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'label: smoke'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\". In the attributes you can also specify the environment where the tests are run, as well as the branch, plugins, and third-party systems. When the same scope of test cases is executed against different environments, versions, or with different plugins, it is beneficial to indicate these differences in the attributes.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6JxigKYbkzoH5suIMsSThF\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"So, we have completed the preconditions, and now we are ready to create the test automation results dashboard. We recommend creating different dashboards for various purposes: for regression testing, for specific versions, for unstable tests, etc.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1lolQnY68IuB2PDbouJOVC\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In ReportPortal, you can track test automation metrics using our widgets.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Widgets for tracking test automation\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Component Health Check\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can create this widget using attributes and see which components, functionality, platforms, etc. are not working correctly so you should pay more attention to them.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3mFDnowm9naXOLAYOh8rPE\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Overall Statistics\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This is a summary of test cases with their statuses. In the test result report, you can only set Total/Passed/Failed/Skipped. Additionally, this widget shows the number of bugs categorized by defect type: Product bugs, Automation bugs, and System issues or custom defect types. The widget has clickable sections, allowing you to navigate and view test failures and their causes. Afterward, post an issue in the bug tracking system (BTS) for all Product and Automation bugs or link the already created tickets to the failed items in ReportPortal.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4ni9dNIqFOWdhuWUv3x5EK\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\rUnique Bugs Table \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"This widget displays existing bugs created in the BTS. It enables us to track the issues within our product. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"2ybWGW8dyXbLEid1nzACpI\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Passing Rate Summary \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Initially, it is sufficient to understand the proportion of Passed/Failed cases.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Here, you need to pay attention to the failures: are there any tests that are constantly failing and that don’t yet have a defect type?\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4egJWwjKdLnoh1FZXi3m40\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Flaky test cases table \\r  \\r\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The widget displays the most unstable tests.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"It's not just a failure when we know, for example, that it's an automation bug. But if a test first passed, then failed, and then passed again, it means the issue is either in the test itself or in the environment. We need to investigate everything we see here.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3uHxxD6GW09TA6jIL1kshz\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Cumulative trend chart\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You only need to build it once to obtain launch summary statistics with one attribute. For example, if we have an \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'environment: dev'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" attribute, it's convenient to view statistics for this environment.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In the ReportPortal, there's a peculiar feature: if a launch has a certain attribute, and there are no attributes at the step level, then all tests within that launch are associated with that attribute.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Therefore, if we have an \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"'environment: dev'\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" attribute, the system treats all tests within that launch as if they also have this attribute. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4E7UzDHdqkjzOBI9U7Xvmf\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In summary, test automation metrics help to enhance test automation, and as a result, contribute to the creation of high-quality software.\\r\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"}"},"title":{"title":"How to create a QA metrics dashboard in ReportPortal"},"leadParagraph":{"leadParagraph":"Nowadays, test automation is an essential part of the software development process. For effective test automation, it is crucial to build a QA metrics dashboard. \n\nBut firstly, we have to complete some prerequisites."},"category":["Best Practices"],"featuredImage":{"file":{"url":"//images.ctfassets.net/1n1nntnzoxp4/4BXb5XyjHaWoKZDWt78h6n/42688cc418cd33231ce60a5ff154ce6f/metrics.svg"}},"slug":"how-to-create-a-qa-metrics-dashboard-in-reportportal"}]}}}